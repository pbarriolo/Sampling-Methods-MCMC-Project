{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import and Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_interpretator=\"/home/onyxia/work/Sampling-Methods-MCMC-Project/Manifold_MALA/mMALA_Vistual_Env/bin/python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set mMALA Requirement Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(X,Y,beta_):\n",
    "    N,k=X.shape\n",
    "    beta_T=beta_.transpose()\n",
    "    X_T=X.transpose()\n",
    "\n",
    "    log_likeli=np.round((beta_T@X_T)@Y,5)\n",
    "\n",
    "    for n in range(N):\n",
    "        log_likeli=log_likeli-np.log(1+np.round(np.exp(beta_T@(X[n,:])).transpose(),5))\n",
    "\n",
    "    return np.round(log_likeli,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2) (500,) (2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-462.60198"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# application\n",
    "X=np.random.randn(500,2)\n",
    "Y=np.random.randn(500)#.reshape(3,1)\n",
    "beta_=np.ones(2)#.reshape(3,1)\n",
    "\n",
    "print(X.shape,Y.shape,beta_.shape)\n",
    "log_likelihood(X,Y,beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2\n",
    "mu=np.zeros(k)\n",
    "variance_=np.identity(k)\n",
    "sigma_square=1  # \" dans la papier sigma_square=100\"\n",
    "def get_densite_value(betha_,mu=mu,variance_=sigma_square*np.identity(k)):\n",
    "    k=len(beta_)\n",
    "    det_=np.linalg.det(variance_)\n",
    "    inv_variance_=np.linalg.inv(variance_)\n",
    "    gap=betha_-mu\n",
    "    gap_T=gap.transpose()\n",
    "    pi_=np.round(np.pi,3)\n",
    "    const1=np.sqrt(((2*pi_)**(k)))\n",
    "    normalisation_constante=np.round((1/(const1*det_)),3)\n",
    "    value=(-1/2)*(gap@inv_variance_@gap_T)\n",
    "    densite_value=normalisation_constante*np.exp(value)\n",
    "\n",
    "    return np.round(densite_value,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05849"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_densite_value(beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.367503508616934"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_densite_value(beta_)*2*np.pi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_fun_value(X_i,betha_):\n",
    "    betha_T=betha_.transpose()\n",
    "    X_i_T=betha_.transpose()\n",
    "    x=betha_T@X_i_T\n",
    "    return np.round(1/(1+np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1=X[1]\n",
    "link_fun_value(X_1,beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Lambda_Matrix(X,sigma_square,betha_):\n",
    "    N=X.shape[0]\n",
    "    left_real_values=[link_fun_value(X[i,:],betha_) for i in range(N)]\n",
    "    real_values=[left_real_values[i]*(1-left_real_values[i]) for i in range(N)]\n",
    "    Lambda_matrix=np.diag(real_values)\n",
    "\n",
    "    return Lambda_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda_Matrix=get_Lambda_Matrix(X,sigma_square,beta_)\n",
    "Lambda_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tensor_metric_G(X,sigma_square,beta_):\n",
    "    k=len(beta_)\n",
    "    Lambda_Matrix=get_Lambda_Matrix(X,sigma_square,beta_)\n",
    "    X_t=X.transpose()\n",
    "    G_of_beta=X_t@(Lambda_Matrix@X)-sigma_square*np.identity(k)\n",
    "\n",
    "    return G_of_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  0.],\n",
       "       [ 0., -1.]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_of_beta=Tensor_metric_G(X,sigma_square,beta_)\n",
    "G_of_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_V_i(X,i,beta_):\n",
    "    N=X.shape[0]\n",
    "    diag_elts=[(1-2*link_fun_value(X[n],beta_))*X[n,i] for n in range(N)]\n",
    "    V_i_Matrix=np.diag(diag_elts)\n",
    "    return V_i_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.53025198,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.68653626,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.36496424, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.17802523,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "        -1.13906968,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.71486907]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "compute_V_i(X,i,beta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_G_partial_derivative(X,i,beta_):\n",
    "    X_t=X.transpose()\n",
    "    Lambda_Matrix=get_Lambda_Matrix(X,sigma_square,beta_)\n",
    "    V_i_Matrix=compute_V_i(X,i,beta_)\n",
    "    G_partial_derivative_Matrix=X_t@Lambda_Matrix@V_i_Matrix@X\n",
    "\n",
    "    return G_partial_derivative_Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_partial_derivative_Matrix=get_G_partial_derivative(X,i,beta_)\n",
    "G_partial_derivative_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.zeros((2,3))\n",
    "x.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log_likelihood_gradient(X,Y,beta_):\n",
    "    N=X.shape[0]\n",
    "    X_Transpose=X.transpose()\n",
    "    X_n=np.zeros(k)\n",
    "    gradien_value=X_Transpose@Y\n",
    "    for n in range(N):\n",
    "        X_n=X[n,:]\n",
    "        gradien_value=gradien_value-link_fun_value(X_n,beta_)*(X_n.transpose())\n",
    "\n",
    "    return gradien_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.79232372,   0.90153572])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradien_value=Log_likelihood_gradient(X,Y,beta_)\n",
    "gradien_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal_Distribution_mean(X,Y,beta_,learning_rate):\n",
    "    N,k=X.shape\n",
    "    e=learning_rate\n",
    "    G=Tensor_metric_G(X,sigma_square,beta_)\n",
    "    inv_G=np.linalg.inv(G)\n",
    "\n",
    "    term2=(1/2)*(e**2)*inv_G@Log_likelihood_gradient(X,Y,beta_)\n",
    "    term3=np.zeros(k)\n",
    "    term4=np.zeros(k)\n",
    "    for j in range(k):\n",
    "        term3=term3-(e**2)*(inv_G@get_G_partial_derivative(X,j,beta_)@inv_G)[:,j]\n",
    "    for j in range(k):\n",
    "        terme4=term4+(e**2)*inv_G[:,j]*np.trace(inv_G@get_G_partial_derivative(X,j,beta_))\n",
    "\n",
    "    proposal_mean=beta_+term2+term3+term4\n",
    "    return proposal_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.39616186, 0.54923214])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_mean=proposal_Distribution_mean(X,Y,beta_,learning_rate=1)\n",
    "proposal_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_sqrt(X):\n",
    "    U, s, V = np.linalg.svd(X)\n",
    "\n",
    "# Racine carrée des valeurs singulières\n",
    "    s_sqrt = np.sqrt(s)\n",
    "\n",
    "# Reconstruction de la matrice racine carrée\n",
    "    X_sqrt = U.dot(np.diag(s_sqrt)).dot(V)\n",
    "\n",
    "    return X_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal_Distribution_variance_matrix_fun(X,beta_,sigma_square,learning_rate):\n",
    "    e=learning_rate\n",
    "    G=Tensor_metric_G(X,sigma_square,beta_)\n",
    "    inv_G=np.linalg.inv(G)\n",
    "    inv_G_sqrt=get_matrix_sqrt(inv_G)\n",
    "    \n",
    "    return e*inv_G_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_drawner(X,Y,beta_,learning_rate=1):\n",
    "    e=learning_rate\n",
    "    N,k=X.shape\n",
    "    mean_=proposal_Distribution_mean(X,Y,beta_,learning_rate=e)\n",
    "    variance=e*proposal_Distribution_variance_matrix_fun(X,beta_,sigma_square,learning_rate)\n",
    "    Z=np.random.randn(k)\n",
    "    proposed_teta=+variance@Z\n",
    "    \n",
    "    return proposed_teta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55613651, -0.43205642])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetaStart=beta_drawner(X,Y,beta_,learning_rate=1)\n",
    "thetaStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2\n",
    "sigma_square=1\n",
    "def Acceptance_Rati(thetaStart, theta_,X,Y,mu_prior=np.zeros(k),variance_=sigma_square*np.identity(k),learning_rate=1):\n",
    "    LL_theta=log_likelihood(X,Y,theta_)\n",
    "    LL_theta_start=log_likelihood(X,Y,thetaStart)\n",
    "\n",
    "    teta_mu_proposal=proposal_Distribution_mean(X,Y,thetaStart,learning_rate)\n",
    "    teta_variance_propsal=proposal_Distribution_variance_matrix_fun(X,thetaStart,sigma_square,learning_rate)\n",
    "    tetaStart_mu_proposal=proposal_Distribution_mean(X,Y,beta_,learning_rate)\n",
    "    tetaStar_variance_propsal=proposal_Distribution_variance_matrix_fun(X,beta_,sigma_square,learning_rate)\n",
    "\n",
    "    \n",
    "    p_teta=get_densite_value(theta_,mu=mu_prior,variance_=variance_)\n",
    "    q_teta=get_densite_value(theta_,mu=teta_mu_proposal,variance_=teta_variance_propsal)\n",
    "\n",
    "    p_teta_start=get_densite_value(theta_,mu=mu_prior,variance_=variance_)\n",
    "    q_teta_start=get_densite_value(theta_,mu=tetaStart_mu_proposal,variance_=tetaStar_variance_propsal)\n",
    "\n",
    "    acceptance_rate=np.round(LL_theta_start+np.log(p_teta_start)+np.log(q_teta_start)-LL_theta-np.log(p_teta)-np.log(q_teta),5)\n",
    "\n",
    "    return acceptance_rate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.79357"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acceptance_rate_=Acceptance_Rati(thetaStart, beta_,X,Y,mu_prior=np.zeros(k),variance_=sigma_square*np.identity(k),learning_rate=1)\n",
    "acceptance_rate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73972379, -1.39021978])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposed_beta=beta_drawner(X,Y,beta_,learning_rate=1)\n",
    "proposed_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\" puique les deux lois proposal and prior sont des loi de normales alors , on a beasoin d'implémenter une fonction\n",
    "calcul le log prior pour la loi propsal , on juste utiliser celle basée sur la loi à priori en définisant la moyenne et la \n",
    "variance des dlois comme des arguments .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_mMALA(X,Y,beta_,learning):\n",
    "    # sample new teta base on the previous teta\n",
    "    N,k=X.shape\n",
    "    thetaStart=beta_drawner(X,Y,beta_,learning_rate=1)\n",
    "    acceptance_rate_=Acceptance_Rati(thetaStart, beta_,X,Y,mu_prior=np.zeros(k),variance_=sigma_square*np.identity(k),learning_rate=1)\n",
    "    rand=np.random.uniform(0, 1)\n",
    "    if (acceptance_rate_>0) or (acceptance_rate_>np.log(rand)):\n",
    "        return thetaStart\n",
    "    else:\n",
    "        return beta_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 DGP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1996\n",
    "np.random.seed(seed)\n",
    "rd.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np \n",
    "import random as rd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=500\n",
    "k=2\n",
    "def get_covariate_data(N=N,k=k):\n",
    "    data=np.random.randn(N,k)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_fun(x):\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=get_covariate_data(N,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N,k=X.shape\n",
    "teta=np.array([i/k for i in range(k)])\n",
    "def get_output(data,teta):\n",
    "    noise_value=np.random.randn(N).reshape(N,1)\n",
    "    teta=teta.reshape(k,1)\n",
    "    data=data.reshape(N,k)\n",
    "    value_=data@teta   #+noise_value\n",
    "    Y=np.array([indicator_fun(value_[i]) for i in range(N)])\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=get_output(X,teta)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.57285766,  0.15460676],\n",
       "        [ 1.88962132, -0.61375061],\n",
       "        [-0.19281915, -0.48191554],\n",
       "        [ 1.33225346,  0.17746124],\n",
       "        [-0.36277234,  0.33420864]]),\n",
       " array([1, 0, 0, 1, 1]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5],Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I Manifold MALA Alogrithsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mMALA_MarkovCHaine(X,Y,B=1000):\n",
    "    N,k=X.shape\n",
    "    theta_current=np.zeros(k)\n",
    "    mc_teta=[]\n",
    "    for b in range(B):\n",
    "        theta_current=one_step_mMALA(X,Y,theta_current,learning=0.1)\n",
    "        mc_teta.append(theta_current)    \n",
    "    return   mc_teta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_237247/2740140276.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  densite_value=normalisation_constante*np.exp(value)\n",
      "/tmp/ipykernel_237247/882416620.py:19: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  acceptance_rate=np.round(LL_theta_start+np.log(p_teta_start)+np.log(q_teta_start)-LL_theta-np.log(p_teta)-np.log(q_teta),5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0., 0.]),\n",
       " array([0., 0.]),\n",
       " array([0., 0.]),\n",
       " array([0., 0.]),\n",
       " array([0., 0.]),\n",
       " array([0., 0.]),\n",
       " array([0., 0.]),\n",
       " array([0., 0.]),\n",
       " array([0., 0.]),\n",
       " array([0., 0.])]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mMALA_MarkovCHaine(X,Y,B=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
